configfile: "config.yaml"

from os.path import *
import glob


FILES = glob.glob(config["input_dir"] + "DRG_037/**/DRG_037-F01_LIBx1_FINAL_b37_PE.aln.RG.dupes_marked.bam", recursive = True)

d = {}
for f in FILES:
	d[basename(f)[:-4]] = f

rule all:
	input:
		[
			# config["dest_dir_BAMs"] + s + ".md.bam" for s in d.keys()
			# config["dest_dir_BAMs"] + s + ".clean.bam" for s in d.keys()
			config["dest_dir_metrics"] + s + ".validate_output" for s in d.keys()
		] + [
			config["dest_dir_metrics"] + s + ".wgs_metrics.txt" for s in d.keys()
		] + [
			config["dest_dir_metrics"] + s + ".multiple_metrics" for s in d.keys()
		] + [
			config["dest_dir_BAMs"] + s + ".cram" for s in d.keys()
		]



# rule sort_bam:
# 	input: config["input_dir"] + "{run}/{sample}/{basename}.bam"
# 	output: "{run}/{sample}/bams_pre/{basename}.sorted.bam"
# 	# shell: "samtools sort -o {output} -n {input}"
# 	shell: "java -Xmx2g -jar " + config["path_picard"] + " SortSam SO=queryname I={input} O={output}"

# rule fixmate:
# 	input: "{run}/{sample}/bams_pre/{basename}.sorted.bam"
# 	output: "{run}/{sample}/bams_pre/{basename}.fixed_mate.bam"
# 	# shell: "samtools fixmate {input} {output}"
# 	shell: "java -Xmx2g -jar " + config["path_picard"] + " FixMateInformation I={input} O={output}"


# another option to the following step is samtools collate + samtools fastq
rule picard_SamToFastq:
	input:
		lambda wildcards: d[wildcards.sample]
	output:
		fq1 = config["dest_dir_FASTQs"] + "{sample}.R1.fq.gz",
		fq2 = config["dest_dir_FASTQs"] + "{sample}.R2.fq.gz",
		fq0 = config["dest_dir_FASTQs"] + "{sample}.unpaired.fq.gz"
	shell: "java -Xmx2g -jar " + config["path_picard"] + " SamToFastq I={input} FASTQ={output.fq1} SECOND_END_FASTQ={output.fq2} UNPAIRED_FASTQ={output.fq0}"


rule realign:
	input:
		fq1 = config["dest_dir_FASTQs"] + "{sample}.R1.fq.gz",
		fq2 = config["dest_dir_FASTQs"] + "{sample}.R2.fq.gz",
		ref = config["ref_fa"]
	output:
		config["dest_dir_BAMs"] + "{sample}.sam"
	shell:
		"bwa mem {input.ref} {input.fq1} {input.fq2} > {output}"


rule cram:
	input:
		sam = config["dest_dir_BAMs"] + "{sample}.sam",
		ref = config["ref_fa"]
	output:
		config["dest_dir_BAMs"] + "{sample}.cram"
	shell:
		config["path_to_scramble"] + " -I sam -O cram -7 -V 3.0 -t 32 -B -r {input.ref} {input.sam} {output}"



rule sort_bam:
	input: config["dest_dir_BAMs"] + "{sample}.sam"
	output: config["dest_dir_BAMs"] + "{sample}.sorted.bam"
	shell: "java -Xmx2g -jar " + config["path_picard"] + " SortSam SO=coordinate I={input} O={output}"


rule mark_duplicates:
	input: config["dest_dir_BAMs"] + "{sample}.sorted.bam"
	output:
		bam = config["dest_dir_BAMs"] + "{sample}.md.bam",
		metrics = config["dest_dir_metrics"] + "{sample}.duplicate_metrics.txt"
	shell:
		"java -Xmx2g -jar " + config["path_picard"] + " MarkDuplicates "
		"I={input} "
		"O={output.bam} "
		"M={output.metrics} "
		"VALIDATION_STRINGENCY=SILENT REMOVE_DUPLICATES=false"


rule cleanSam:
	input:
		bam = config["dest_dir_BAMs"] + "{sample}.md.bam",
		ref = config["ref_fa"]
	output: config["dest_dir_BAMs"] + "{sample}.clean.bam"
	shell:
		"java -Xmx2g -jar " + config["path_picard"] + " CleanSam "
		"I={input.bam} "
		"O={output} "
		"R={input.ref}"


rule ValidateSamFile:
	input: config["dest_dir_BAMs"] + "{sample}.clean.bam"
	output: config["dest_dir_metrics"] + "{sample}.validate_output"
	shell: "java -Xmx2g -jar " + config["path_picard"] + " ValidateSamFile I={input} MODE=SUMMARY > {output} "



# collect multiple metrics, verifyBamID...
rule verifyBamID:
	input:
		bam = config["dest_dir_BAMs"] + "{sample}.clean.bam",
		vcf = config["vcf_ref_verifyBamID"]
	output: config["dest_dir_metrics"] + "{sample}.verifyBamID"
	shell:
		"verifyBamID "
		"--vcf {input.vcf} "
		"--bam {input.bam} "
		"--out {output} "
		"--ignoreRG --verbose"



# IMPORTANT!! in WES we must use Picard CollectHsMetrics instead
rule CollectWgsMetrics:
	input:
		bam = config["dest_dir_BAMs"] + "{sample}.clean.bam",
		ref = config["ref_fa"]
	output: config["dest_dir_metrics"] + "{sample}.wgs_metrics.txt"
	shell:
		"java -Xmx12g -jar " + config["path_picard"] + " CollectWgsMetrics "
		"R={input.ref} I={input.bam} O={output}"



rule CollectMultipleMetrics:
	input:
		bam = config["dest_dir_BAMs"] + "{sample}.clean.bam",
		ref = config["ref_fa"]
	output: config["dest_dir_metrics"] + "{sample}.multiple_metrics"
	shell:
		"java -Xmx12g -jar " + config["path_picard"] + " CollectMultipleMetrics"
		"R={input.ref} I={input.bam} O={output} "
		"PROGRAM=null"
		"PROGRAM=CollectAlignmentSummaryMetrics "
		"PROGRAM=CollectInsertSizeMetrics "
		"PROGRAM=CollectGcBiasMetrics "
		"METRIC_ACCUMULATION_LEVEL=null "
		"METRIC_ACCUMULATION_LEVEL=READ_GROUP "
		"METRIC_ACCUMULATION_LEVEL=SAMPLE "
		"VALIDATION_STRINGENCY=SILENT "



rule flagstats:
	input:
		sam = config["dest_dir_BAMs"] + "{sample}.sam",
		cram = config["dest_dir_BAMs"] + "{sample}.cram",
		original_bam = lambda wildcards: d[wildcards.sample]
	output:
		flagstat_sam = config["dest_dir_BAMs"] + "{sample}.flagstat_sam",
		flagstat_cram = config["dest_dir_BAMs"] + "{sample}.flagstat_cram",
		flagstat_original_bam = config["dest_dir_BAMs"] + "{sample}.flagstat_original_bam"
	shell:
		"samtools flagstat {input.sam} > {output.flagstat_sam} && "
		"samtools flagstat {input.cram} > {output.flagstat_cram} && "
		"samtools flagstat {input.original_bam} > {output.flagstat_original_bam} "


# compare the flagstats of the original bam vs new bam
# check the metrics and add the sample to a exclude.txt file
# open fastqs with FastQC > possibly remove adapters with cutadapt.

# snakemake -s part1.snake -npF



